#!/usr/bin/env python3

import argparse
from graditudelib import normalize
from graditudelib import visualizing_kinetics
from graditudelib import k_means
from graditudelib import elbow_curve
from graditudelib import silhouette
from graditudelib import tSNE
from graditudelib import hierarchical_clustering
from graditudelib import PCA_analysis
from graditudelib import scaling
from graditudelib import robust_regression
from graditudelib import DBSCAN_clustering
from graditudelib import Clustering
from graditudelib import min_row_sum
from graditudelib import t_sne_colored_list_clustering_features
from graditudelib import correlation_between_genes
from graditudelib import selecting_ncRNAs
from graditudelib import modify_input


def main():
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(help="commands")

    modify_input_parser = subparsers.add_parser("filtering_tables")
    modify_input_parser.set_defaults(func=filtering_tables)
    modify_input_parser.add_argument('--feature_count_table', '-f', required=True)
    modify_input_parser.add_argument("--ref_feature_count_table", "-r", required=True)
    modify_input_parser.add_argument("--filtered_ref_feature_count_table", "-fr", required=True)
    modify_input_parser.add_argument("--filtered_feature_count_table", "-ff", required=True)
    modify_input_parser.add_argument("--column_to_drop", "-c", default=None)

    # Currently done with DESeq2's approach - maybe add further options
    normalize_parser = subparsers.add_parser("normalize")
    normalize_parser.set_defaults(func=normalize_table)
    normalize_parser.add_argument('--feature_count_table', '-f', required=True)
    normalize_parser.add_argument('--feature_count_start_column', '-fc', type=int)
    normalize_parser.add_argument("--ref_feature_count_table", "-r", required=True)
    normalize_parser.add_argument("--ref_feature_count_start_column", "-rc", default=1, type=int)
    normalize_parser.add_argument("--normalized_table", "-o", required=True)
    normalize_parser.add_argument("--size_factor_table", "-s", default=None)

    scaling_parser = subparsers.add_parser("scaling")
    scaling_parser.set_defaults(func=scaling)
    scaling_parser.add_argument('--feature_count_table', '-f', required=True)
    scaling_parser.add_argument('--feature_count_start_column', '-fc', required=True)
    scaling_parser.add_argument("--scaled_table", "-o", required=True)
    scaling_parser.add_argument(
        "--scaling_method", "-sm", required=True,
        choices=["no_scaling", "to_max", "to_range", "log_10_to_max"])
    scaling_parser.add_argument("--pseudo_count", '-p', type=int, default=1)

    robust_regression_parser = subparsers.add_parser("robust_regression")
    robust_regression_parser.set_defaults(func=run_robust_regression)
    robust_regression_parser.add_argument('--ref_feature_count_table', '-r', required=True)
    robust_regression_parser.add_argument('--concentration_table', '-c', required=True)
    robust_regression_parser.add_argument("--number_of_outliers", "-n", required=True, type=int)
    robust_regression_parser.add_argument("--outliers_table", '-o', required=True)
    robust_regression_parser.add_argument('--number_of_ercc_in_common', '-nc', type=int)
    # robust_regression_parser.add_argument("--plot_outliers", '-p', default=False,
    #                                       help='plot the outliers. Default is False')

    correlation_gene_gene_parser = subparsers.add_parser("correlation_gene_gene")
    correlation_gene_gene_parser.set_defaults(func=run_correlation_gene_gene)
    correlation_gene_gene_parser.add_argument('--feature_count_table', '-f', required=True)
    correlation_gene_gene_parser.add_argument('--feature_count_start_column', '-fc', required=True)
    correlation_gene_gene_parser.add_argument('--output_file', '-o', required=True)

    selecting_specific_features = subparsers.add_parser("selecting_specific_features")
    selecting_specific_features.set_defaults(func=select_specific_features)
    selecting_specific_features.add_argument('--normalized_table', '-n', required=True)
    selecting_specific_features.add_argument('--feature_count_start_column', '-fc', required=True, type=int)
    selecting_specific_features.add_argument('--feautures', '-f', required=True, nargs="+")
    selecting_specific_features.add_argument('--output_table', '-o', required=True)

    # For each fraction generate/write--output_format/
    # - Histogram 
    # - Max, mix, median, average
    # - all again all correlation (scatter plot, Pearson and Spearman cor. factor) 
    # generate_table_stats_parser = subparsers.add_parser("generate_table_stats")
    # generate_table_stats_parser.set_defaults(func=generate_table_stats)
    # generate_table_stats_parser.add_argument("--feature_count_table", "-c", required=True)
    # generate_table_stats_parser.add_argument("--feature_count_table", "-c", required=True)
    # generate_table_stats_parser.add_argument("--output_file", "-o" required=True)

    # histogram_of_fraction_parser = subparsers.add_parser("plot_histograms")
    # histogram_of_fraction_parser.set_defaults(func=plot_histograms)
    # histogram_of_fraction_parser.add_argument("--feature_count_table", "-c", required=True)
    # histogram_of_fraction_parser.add_argument('--feature_count_start_column', default=1)
    #
    modify_input_with_min_row_sum = subparsers.add_parser("find_min_rows")
    modify_input_with_min_row_sum.set_defaults(func=find_min_rows)
    modify_input_with_min_row_sum.add_argument("--feature_count_table", "-f", required=True)
    modify_input_with_min_row_sum.add_argument('--feature_count_start_column', "-fc", required=True, type=int)
    modify_input_with_min_row_sum.add_argument("--min_row", '-m', required=True, type=int)
    modify_input_with_min_row_sum.add_argument("--output_file", "-o", required=True)

    plot_kinetics_parser = subparsers.add_parser("plot_kinetics")
    plot_kinetics_parser.set_defaults(func=plot_kinetics)
    plot_kinetics_parser.add_argument("--feature_count_table", "-f", required=True)
    plot_kinetics_parser.add_argument("--gene_name", "-gene", required=True)
    plot_kinetics_parser.add_argument('--feature_count_start_column', "-fc", required=True)
    plot_kinetics_parser.add_argument("--output_plot", "-o", required=True)
    plot_kinetics_parser.add_argument("--output_format", '-format', choices=["html", "pdf"],
                                      default="html")

    clustering_parser = subparsers.add_parser("clustering")
    clustering_parser.set_defaults(func=clustering)
    clustering_parser.add_argument("--feature_count_table", "-f", required=True)
    clustering_parser.add_argument("--feature_count_start_column", "-fc", required=True, type=int)
    clustering_parser.add_argument("--number_of_clusters", '-nc', required=True, type=int)
    clustering_parser.add_argument("--pseudo_count", "-p", type=int,
                                   default=1)
    clustering_parser.add_argument("--clustering_methods", "-cm", required=True,
                                   choices=["k-means", "DBSCAN", 'hierarchical_clustering'])
    clustering_parser.add_argument("--epsilon", "-e", default=False,
                                   help='only for DBSCAN clustering', type=float)
    clustering_parser.add_argument("--min_samples", '-ms', default=False,
                                   help='only for DBSCAN clustering', type=int)
    clustering_parser.add_argument(
        "--scaling_method", '-sm', required=True,
        choices=["no_normalization", "normalized_to_max", "normalized_to_range", "log10", "log2"])
    clustering_parser.add_argument("--output_file", "-o", required=True)

    k_means_clustering_parser = subparsers.add_parser("k_means_clustering")
    k_means_clustering_parser.set_defaults(func=k_means_clustering)
    k_means_clustering_parser.add_argument("--feature_count_table", "-f", required=True)
    k_means_clustering_parser.add_argument("--feature_count_start_column", "-fc", default=1, type=int)
    k_means_clustering_parser.add_argument(
        "--scaling_method", "-sm", required=True,
        choices=["no_normalization", "normalized_to_max", "normalized_to_range", "log10", "log2"])
    k_means_clustering_parser.add_argument("--pseudo_count", "-p", type=int, default=1)
    k_means_clustering_parser.add_argument("--number_of_clusters", '-nc', required=True, type=int)
    k_means_clustering_parser.add_argument("--output_file", "-o", required=True)

    k_means_clustering_elbow_parser = subparsers.add_parser("k_means_clustering_elbow")
    k_means_clustering_elbow_parser.set_defaults(func=generate_k_means_clustering_elbow)
    k_means_clustering_elbow_parser.add_argument("--feature_count_table", "-f", required=True)
    k_means_clustering_elbow_parser.add_argument("--feature_count_start_column", "-fc", required=True)
    k_means_clustering_elbow_parser.add_argument("--min_number_of_clusters", '-min', required=True, type=int)
    k_means_clustering_elbow_parser.add_argument("--max_number_of_clusters", '-max', required=True, type=int)
    k_means_clustering_elbow_parser.add_argument("--output_plots1", '-o1', required=True)
    k_means_clustering_elbow_parser.add_argument("--output_plots2", '-o2', required=True)

    silhouette_parser = subparsers.add_parser("silhouette_analysis")
    silhouette_parser.set_defaults(func=silhouette_analysis)
    silhouette_parser.add_argument("--feature_count_table", "-c", required=True)
    silhouette_parser.add_argument("--feature_count_start_column", required=True)
    silhouette_parser.add_argument("--min_number_of_clusters", "-min", required=True, type=int)
    silhouette_parser.add_argument("--max_number_of_clusters", "-max", required=True, type=int)

    hierarchical_clustering_parser = subparsers.add_parser("hierarchical_clustering")
    hierarchical_clustering_parser.set_defaults(func=run_hierarchical_clustering)
    hierarchical_clustering_parser.add_argument("--feature_count_table", "-f", required=True)
    hierarchical_clustering_parser.add_argument("--feature_count_start_column", "-fc", required=True)
    hierarchical_clustering_parser.add_argument("--number_of_clusters", "-nc", required=True, type=int)
    hierarchical_clustering_parser.add_argument("--output_file", "-o", required=True)
    hierarchical_clustering_parser.add_argument(
        "--scaling_method", "-sm", required=True,
        choices=["no_normalization", "normalized_to_max", "normalized_to_range", "log10", 'log2'])
    hierarchical_clustering_parser.add_argument("--pseudo_count", '-p', type=int, default=1)

    dbscan_clustering_parser = subparsers.add_parser("dbscan_clustering")
    dbscan_clustering_parser.set_defaults(func=dbscan_clustering)
    dbscan_clustering_parser.add_argument("--feature_count_table", "-f", required=True)
    dbscan_clustering_parser.add_argument("--feature_count_start_column", "-fc", required=True)
    dbscan_clustering_parser.add_argument(
        "--scaling_method", "-sm", required=True,
        choices=["no_normalization", "normalized_to_max", "normalized_to_range", "log10", "log2"])
    dbscan_clustering_parser.add_argument("--pseudo_count", "-p", required=True)
    dbscan_clustering_parser.add_argument("--epsilon", "-e", required=True, type=float)
    dbscan_clustering_parser.add_argument("--min_samples", "-ms", required=True, type=int)
    dbscan_clustering_parser.add_argument("--output_file", "-o", required=True)

    pca_parser = subparsers.add_parser("pca")
    pca_parser.set_defaults(func=run_pca)
    pca_parser.add_argument("--feature_count_table", "-f", required=True)
    pca_parser.add_argument("--feature_count_start_column", "-fc", required=True, type=int)
    pca_parser.add_argument("--output_file_colorized_by_clusters", "-clusters", required=True)
    pca_parser.add_argument("--output_file_colorized_by_rna_class", "-features", required=True)
    pca_parser.add_argument("--output_file_colorized_by_rna_class_and_list", "-list")

    t_sne_parser = subparsers.add_parser("t_sne")
    t_sne_parser.set_defaults(func=run_t_sne)
    t_sne_parser.add_argument("--feature_count_table", "-f", required=True)
    t_sne_parser.add_argument("--feature_count_start_column", "-fc", required=True)
    t_sne_parser.add_argument("--output_format", "-format", choices=["html", "pdf"],
                              default="html")
    t_sne_parser.add_argument("--output_file", "-o", required=True)
    t_sne_parser.add_argument(
        "--clustering", "-c", required=True,
        choices=["no_cluster", "with_cluster"])

    t_sne_colored_list_clustering_features_parser = subparsers.add_parser("t_sne_colored_using_different_methods")
    t_sne_colored_list_clustering_features_parser.set_defaults(func=run_t_sne_colored_using_different_methods)
    t_sne_colored_list_clustering_features_parser.add_argument("--feature_count_table", "-f", required=True)
    t_sne_colored_list_clustering_features_parser.add_argument("--feature_count_start_column", "-fc", required=True,
                                                               type=int)
    t_sne_colored_list_clustering_features_parser.add_argument("--perplexity", "-pp", required=True, type=int)
    t_sne_colored_list_clustering_features_parser.add_argument("--s_rna_list_files", "-list", default=False, nargs="+",
                                                               help='tSNE colored using a certain list, DEFAULT false')

    t_sne_colored_list_clustering_features_parser.add_argument("--output_file1", "-o1", default=False,
                                                               help="output colorized using clusters information")
    t_sne_colored_list_clustering_features_parser.add_argument("--output_file2", "-o2", default=False,
                                                               help="output colorized using attributes information")
    t_sne_colored_list_clustering_features_parser.add_argument("--output_file3", "-o3", default=False,
                                                               help="output colorized using list ")

    # version_parser = subparsers.add_parser("version")
    # version_parser.set_defaults(func=show_version)

    # This is nice-to-have but not essential!
    # This subcommand will help to select rows and columns to build a
    # defined count table. It will also help to translate attribute
    # column into other columns (e.g. with gene names)
    # rearrange_count_table_parser = subparsers.add_parser("rearrange_count_table")

    args = parser.parse_args()
    if "func" in dir(args):
        args.func(args)
    else:
        parser.print_help()


def filtering_tables(args):
    modify_input.filtering_input(args.feature_count_table, args.ref_feature_count_table,
                                 args.filtered_ref_feature_count_table, args.filtered_feature_count_table,
                                 args.column_to_drop)


def normalize_table(args):
    normalize.normalized_count_table(
        args.feature_count_table, args.feature_count_start_column,
        args.ref_feature_count_table, args.ref_feature_count_start_column,
        args.normalized_table, args.size_factor_table)


def run_correlation_gene_gene(args):
    correlation_between_genes.correlation(args.feature_count_table, args.feature_count_start_column, args.output_file)


def plot_kinetics(args):
    visualizing_kinetics.plot_kinetics(
        args.feature_count_table, args.gene_name, args.feature_count_start_column)


def select_specific_features(args):
    selecting_ncRNAs.selecting_specific_features(args.normalized_table,
                                                 args.feature_count_start_column, args.features, args.output_file)


def k_means_clustering(args):
    k_means.generate_k_means_clustering(args.feature_count_table,
                                        args.feature_count_start_column,
                                        args.number_of_clusters,
                                        args.output_file,
                                        args.scaling_method, args.pseudo_count)


def generate_k_means_clustering_elbow(args):
    elbow_curve.k_means_clustering_elbow(args.feature_count_table,
                                         args.feature_count_start_column,
                                         args.min_number_of_clusters,
                                         args.max_number_of_clusters, args.output_plots1,
                                         args.output_plots2)


def silhouette_analysis(args):
    silhouette.silhouette_analysis(args.feature_count_table,
                                   args.feature_count_start_column,
                                   args.min_number_of_clusters,
                                   args.max_number_of_clusters)


def run_t_sne(args):
    tSNE.t_sne_analysis(args.feature_count_table,
                        args.feature_count_start_column,
                        args.clustering,
                        args.output_file)


def run_t_sne_colored_using_different_methods(args):
    t_sne_colored_list_clustering_features.t_sne(args.feature_count_table, args.feature_count_start_column,
                                                 args.perplexity, args.s_rna_list_files,
                                                 args.output_file1,
                                                 args.output_file2,
                                                 args.output_file3)


def run_hierarchical_clustering(args):
    hierarchical_clustering.generate_hierarchical_clustering(args.feature_count_table,
                                                             args.feature_count_start_column,
                                                             args.pseudo_count,
                                                             args.scaling_method,
                                                             args.output_file, args.number_of_clusters)


def run_pca(args):
    PCA_analysis.pca(args.feature_count_table,
                     args.feature_count_start_column,
                     args.s_rna_list_files,
                     args.output_file_colorized_by_clusters, args.output_file_colorized_by_rna_class,
                     args.output_file_colorized_by_rna_class_and_list)


def run_scaling(args):
    scaling.scaling(args.feature_count_table,
                    args.feature_count_start_column,
                    args.pseudo_count,
                    args.scaling_method,
                    args.output_file)


def run_robust_regression(args):
    robust_regression.robust_regression(args.ref_feature_count_table,
                                        args.concentration_table, args.number_of_outliers,
                                        args.outliers_table, args.number_of_ercc_in_common)


def dbscan_clustering(args):
    DBSCAN_clustering.generate_dbscan_clustering(args.feature_count_table,
                                                 args.feature_count_start_column, args.scaling_method,
                                                 args.pseudo_count,
                                                 args.epsilon, args.min_samples, args.output_file)


def clustering(args):
    Clustering.clustering(args.feature_count_table, args.feature_count_start_column, args.number_of_clusters,
                          args.pseudo_count, args.clustering_methods,
                          args.epsilon, args.min_samples,
                          args.scaling_method,
                          args.output_file)


def find_min_rows(args):
    min_row_sum.exclude_the_min_row_sum(args.feature_count_table, args.feature_count_start_column, args.min_row,
                                        args.output_file)


main()
