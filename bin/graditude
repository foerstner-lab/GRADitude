#!/usr/bin/env python3

"""GRADitude: a computational tool for the analysis of GRAD-seq data"""

import argparse
import bokeh.palettes
from graditudelib import normalize
from graditudelib import visualizing_kinetics
from graditudelib import elbow_curve
from graditudelib import silhouette
from graditudelib import PCA_analysis
from graditudelib import scaling
from graditudelib import robust_regression
from graditudelib import Clustering
from graditudelib import min_row_sum
from graditudelib import t_sne_colored_list_clustering_features
from graditudelib import correlation_between_genes
from graditudelib import selecting_ncRNAs
from graditudelib import min_row_sum_ercc_table
from graditudelib import correlation_rna_protein
from graditudelib import plot_network_graph
from graditudelib import distribution_correlation
from graditudelib import t_sne_proteins_data
from graditudelib import clustering_proteins
from graditudelib import correlation_specific_gene
from graditudelib import interactive_tsne_plot
from graditudelib import heatmap
from graditudelib import correlation_replicates_sequencing_data
from graditudelib import projectcreator
from graditudelib import dropping_specific_columns

__author__ = "Silvia Di Giorgio <digiorgio@zbmed.de>, " \
             "Konrad Foerstner <konrad@foerstner.org>"
__license__ = "ISC license"
__email__ = "digiorgio@zbmed.de"


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--version", "-v", default=False, action="store_true",
        help="show version")
    subparsers = parser.add_subparsers(help="commands")

    create_parser = subparsers.add_parser("create")
    create_parser.set_defaults(func=create_project)
    create_parser.add_argument('--create_graditude_folder',
                               required=False,
                               default="GRADitude")

    min_row_sum_ercc_table_parser = subparsers.add_parser("min_row_sum_ercc",
                                                          help="Filter the ERCC table based on the min row sum. "
                                                               "It calculates the sum row_wise and discard the rows "
                                                               "with a sum below the threshold specified")
    min_row_sum_ercc_table_parser.set_defaults(func=filtering_tables)
    min_row_sum_ercc_table_parser.add_argument("--ref_feature_count_table", "-r",
                                               required=True,
                                               help="ERCC reads table")
    min_row_sum_ercc_table_parser.add_argument("--min_row_sum", "-m", type=int,
                                               default=100, help="Specify the threshold we would like"
                                                                 " to apply")
    min_row_sum_ercc_table_parser.add_argument("--filtered_ref_feature_count_table", "-fr",
                                               required=True, help="Filtered ERCC reads table as output")

    modify_input_with_min_row_sum_parser = subparsers.add_parser("min_row_sum",
                                                                 help="Filter the gene quantification table based on "
                                                                      "the min row sum. It "
                                                                      "calculates the sum row_wise "
                                                                      "and discard the rows with "
                                                                      "a sum below the threshold specified")
    modify_input_with_min_row_sum_parser.set_defaults(func=find_min_rows)
    modify_input_with_min_row_sum_parser.add_argument("--feature_count_table", "-f", required=True,
                                                      help="Gene quantification table")
    modify_input_with_min_row_sum_parser.add_argument('--feature_count_start_column', "-fc", required=True, type=int,
                                                      help="Specify the number of "
                                                           "the column with the first fraction")
    modify_input_with_min_row_sum_parser.add_argument('--feature_count_end_column', "-fe", required=True, type=int,
                                                      help="Specify the number of "
                                                           "the last fraction we would like to consider in the"
                                                           " analysis", default=False)
    modify_input_with_min_row_sum_parser.add_argument("--min_row", '-m', required=True, type=int, default=100,
                                                      help="Specify the threshold we would like"
                                                           " to apply")
    modify_input_with_min_row_sum_parser.add_argument("--output_file", "-o", required=True,
                                                      help="Filtered table as output")

    dropping_specific_columns_parser = subparsers.add_parser("drop_column",
                                                             help="It filters a table dropping a specific column."
                                                                  "It is usually used to drop the lysate column"
                                                                  "that is not required for the downstream analysis "
                                                             )
    dropping_specific_columns_parser.set_defaults(func=drop_column)
    dropping_specific_columns_parser.add_argument("--feature_count_table", "-f", required=True,
                                                  help="Gene quantification table or ERCC-reads table")
    dropping_specific_columns_parser.add_argument("--column_to_drop", '-c', required=True,
                                                  help="This parameter specify the name of the column you "
                                                       "would like to drop")
    dropping_specific_columns_parser.add_argument("--output_file", "-o", required=True,
                                                  help="Filtered table as output")

    robust_regression_parser = subparsers.add_parser("robust_regression",
                                                     help="It compares the ERCC concentration in mix "
                                                          "with the ERCC reads and take it out the outliers")
    robust_regression_parser.set_defaults(func=run_robust_regression)
    robust_regression_parser.add_argument('--ref_feature_count_table', '-r',
                                          required=True, help='Filtered ERCC reads table')
    robust_regression_parser.add_argument('--concentration_table', '-c',
                                          required=True, help="ERCC concentration table")
    robust_regression_parser.add_argument("--number_of_outliers", "-n",
                                          required=True, type=int, help="Number of outliers")
    robust_regression_parser.add_argument('--number_of_ercc_in_common', '-nc',
                                          type=int, default=18,
                                          help="Number of ERCC considered outliers "
                                               "in common within the different fractions")
    robust_regression_parser.add_argument("--used_mix", "-mix",
                                          required=True, type=int, help="This parameter as to be used "
                                                                        "to define which ERCC mix have been"
                                                                        " used in the experiment,"
                                                                        " in case of mix1 and mix2 the "
                                                                        "--mix is either 3 or 4 ")
    robust_regression_parser.add_argument("--output_table", '-o',
                                          required=True, help="Output table with the inliers ERCC")

    normalize_parser = subparsers.add_parser("normalize", help='This subcommand calculates the ERCC size factor and '
                                                               'normalize the gene quantification '
                                                               'table based on that')
    normalize_parser.set_defaults(func=normalize_table)
    normalize_parser.add_argument('--feature_count_table', '-f', required=True,
                                  help="Filtered gene quantification table")
    normalize_parser.add_argument('--feature_count_start_column', '-fc', type=int,
                                  help="Specify the number of "
                                       "the column with the first fraction")
    normalize_parser.add_argument("--feature_count_end_column", "-fe", type=int,
                                  help="Specify the number of "
                                       "the last fraction we would like to consider in the"
                                       " analysis")
    normalize_parser.add_argument("--ref_feature_count_table", "-r", required=True,
                                  help="ERCC table with the ERCC read-counts")
    normalize_parser.add_argument("--ref_feature_count_start_column", "-rc", default=1, type=int,
                                  help="Specify the number of "
                                       "the column with the first fraction for the ERCC table")
    normalize_parser.add_argument("--ref_feature_count_end_column", "-re", default=-1, type=int,
                                  help="Specify the number of "
                                       "the last fraction we would like to consider in the"
                                       " analysis for the ERCC table")
    normalize_parser.add_argument("--normalized_table", "-o", required=True, help="Table normalized"
                                  )
    normalize_parser.add_argument("--size_factor_table", "-s", default=None, help="Table with all the size factor")

    scaling_parser = subparsers.add_parser("scaling", help="This subcommand scales tables "
                                                           "using different scaling methods")
    scaling_parser.set_defaults(func=run_scaling)
    scaling_parser.add_argument('--feature_count_table', '-f', required=True,
                                help="Normalized gene quantification table or raw tables")
    scaling_parser.add_argument('--feature_count_start_column', '-fc', required=True,
                                help="Specify the number of "
                                     "the column with the first fraction")
    scaling_parser.add_argument('--feature_count_end_column', '-fe', required=True,
                                help="Specify the number of "
                                     "the last fraction we would like to consider in the"
                                     " analysis")
    scaling_parser.add_argument("--pseudo_count", '-p', type=int, default=1,
                                help="the pseudocount is a number that will always be added to each value; "
                                     "Adding this number avoid to have mathematical operation with zeros ")
    scaling_parser.add_argument(
        "--scaling_method", '-sm', required=True,
        choices=["no_normalization", "normalized_to_max", "normalized_to_range", "log10", "log2"],
        help="Define the scaling methods you would like to apply. The user can choose between a normalization "
             "to the maximum value, to a range, a log10 and log 2 normalization. Alternatively the user can decide "
             "to not use any kind of normalization ")
    scaling_parser.add_argument("--scaled_table", "-o", required=True, help="Scaled table as output")

    correlation_gene_gene_parser = subparsers.add_parser("correlation_gene_gene",
                                                         help="correlation all against all ")
    correlation_gene_gene_parser.set_defaults(func=run_correlation_gene_gene)
    correlation_gene_gene_parser.add_argument('--feature_count_table', '-f', required=True)
    correlation_gene_gene_parser.add_argument('--feature_count_start_column', '-fc', required=True)
    correlation_gene_gene_parser.add_argument('--output_file', '-o', required=True)

    selecting_specific_features = subparsers.add_parser("selecting_specific_features",
                                                        help="select specific features in the "
                                                             "normalized table (ncRNAs, CDS, etc.)")
    selecting_specific_features.set_defaults(func=select_specific_features)
    selecting_specific_features.add_argument('--normalized_table', '-n', required=True)
    selecting_specific_features.add_argument('--feature_count_start_column', '-fc',
                                             required=True, type=int)
    selecting_specific_features.add_argument('--features', '-f', nargs='+', required=True)
    selecting_specific_features.add_argument('--output_file', '-o', required=True)

    p_heatmap = subparsers.add_parser("heatmap",
                                      help="correlation all against all ")
    p_heatmap.set_defaults(func=plot_heatmap)
    p_heatmap.add_argument('--feature_count_table', '-f', required=True,
                           help="Filtered gene quantification table")
    p_heatmap.add_argument('--feature_count_start_column', '-fc', type=int,
                           help="number of the column with the first fraction")
    p_heatmap.add_argument("--y_label", "-label", required=True)
    p_heatmap.add_argument("--output_file", "-o", required=True)

    # For each fraction generate/write--output_format/
    # - Histogram 
    # - Max, mix, median, average
    # - all again all correlation (scatter plot, Pearson and Spearman cor. factor) 
    # generate_table_stats_parser = subparsers.add_parser("generate_table_stats")
    # generate_table_stats_parser.set_defaults(func=generate_table_stats)
    # generate_table_stats_parser.add_argument("--feature_count_table", "-c", required=True)
    # generate_table_stats_parser.add_argument("--feature_count_table", "-c", required=True)
    # generate_table_stats_parser.add_argument("--output_file", "-o" required=True)

    # histogram_of_fraction_parser = subparsers.add_parser("plot_histograms")
    # histogram_of_fraction_parser.set_defaults(func=plot_histograms)
    # histogram_of_fraction_parser.add_argument("--feature_count_table", "-c", required=True)
    # histogram_of_fraction_parser.add_argument('--feature_count_start_column', default=1)
    #

    plot_kinetics_parser = subparsers.add_parser("plot_kinetics", help='plot the kinetics')
    plot_kinetics_parser.set_defaults(func=plot_kinetics)
    plot_kinetics_parser.add_argument("--feature_count_table", "-f", required=True)
    plot_kinetics_parser.add_argument("--gene_name", "-gene", required=True)
    plot_kinetics_parser.add_argument('--feature_count_start_column', "-fc", required=True, type=int)
    plot_kinetics_parser.add_argument("--output_plot", "-o", required=True)
    plot_kinetics_parser.add_argument("--output_format", '-format', choices=["html", "pdf"],
                                      default="html")

    clustering_parser = subparsers.add_parser("clustering", help="This subcommand performs unsupervised clustering "
                                                                 "using different algorithm")
    clustering_parser.set_defaults(func=clustering)
    clustering_parser.add_argument("--feature_count_table", "-f", required=True,
                                   help="This parameter specified the table we would like to use."
                                        " It can be the normalized or the raw table")
    clustering_parser.add_argument("--feature_count_start_column", "-fc", required=True,
                                   help="This parameter specified the number of the column with the first fraction",
                                   type=int, )
    clustering_parser.add_argument("--feature_count_end_column", "-fe", required=True,
                                   help="Specify the number of "
                                        "the last fraction we would like to consider in the"
                                        " analysis",
                                   type=int, )
    clustering_parser.add_argument("--number_of_clusters", '-nc', default=False, type=int,
                                   help="This parameter specify the number of clusters, k. It is required only "
                                        "when using k-means and hierarchical clustering algorithm ")
    clustering_parser.add_argument("--pseudo_count", "-p", type=int,
                                   default=1,
                                   help="The pseudocount represent a number that will always be added to each value; "
                                        "Adding this number avoid to have mathematical operation with zero")
    clustering_parser.add_argument("--clustering_methods", "-cm", required=True,
                                   choices=["k-means", "DBSCAN", 'hierarchical_clustering'],
                                   help="The user can choose between 3 clustering  algorithm, k-means clustering, "
                                        "hierarchical clustering and DB-SCAN clustering ")
    clustering_parser.add_argument("--epsilon", "-e", default=False,
                                   help='This parameter is specific for the DBSCAN clustering algorithm. '
                                        'It defines how close points should be '
                                        'in order to be considered part of a cluster. only for DBSCAN clustering'
                                   , type=float)
    clustering_parser.add_argument("--min_samples", '-ms', default=False,
                                   help="This parameter is specific for the DBSCAN clustering algorithm and "
                                        "represent the minimum number of points necessary to form a dense region",
                                   type=int)
    clustering_parser.add_argument(
        "--scaling_method", '-sm', required=True,
        choices=["no_normalization", "normalized_to_max", "normalized_to_range", "log10", "log2"],
        help="Define the scaling methods you would like to apply. The user can choose between a normalization "
             "to the maximum value, to a range, a log10 and log 2 normalization. Alternatively the user can decide "
             "to not use any kind of normalization"
    )
    clustering_parser.add_argument("--output_file", "-o", required=True,
                                   help=
                                   "Output table with a new column containing the number of clusters")

    k_means_clustering_elbow_parser = subparsers.add_parser("clustering_elbow",
                                                            help="This subcommands plot the elbow graph in order "
                                                                 "to choose"
                                                                 "the ideal number of clusters necessary for "
                                                                 "the k-means and the hierarchical clustering ")
    k_means_clustering_elbow_parser.set_defaults(func=generate_k_means_clustering_elbow)
    k_means_clustering_elbow_parser.add_argument("--feature_count_table", "-f", required=True,
                                                 help="Filtered gene quantification table")
    k_means_clustering_elbow_parser.add_argument("--feature_count_start_column", "-fc", required=True,
                                                 help="This parameter specified the number of the column "
                                                      "with the first fraction")
    k_means_clustering_elbow_parser.add_argument("--feature_count_end_column", "-fe", required=True,
                                                 help=" Specify the number of "
                                                      "the last fraction we would like to consider in the"
                                                      " analysis")
    k_means_clustering_elbow_parser.add_argument("--min_number_of_clusters", '-min', required=True, type=int,
                                                 help="Minimum number of clusters that you want to represent "
                                                      "in the plot ")
    k_means_clustering_elbow_parser.add_argument("--max_number_of_clusters", '-max', required=True, type=int,
                                                 help="Maximum number of clusters that you want to represent "
                                                      "in the plot")
    k_means_clustering_elbow_parser.add_argument("--output_plots1", '-o1', required=True,
                                                 help="Plot showing the average within cluster sum "
                                                      "of squares against the number of clusters")
    k_means_clustering_elbow_parser.add_argument("--output_plots2", '-o2', required=True,
                                                 help="Plot showing the percentage of variance explained versus "
                                                      "the number of clusters")

    silhouette_parser = subparsers.add_parser("silhouette_analysis",
                                              help="used to study the "
                                                   "separation distance between the resulting clusters")
    silhouette_parser.set_defaults(func=silhouette_analysis)
    silhouette_parser.add_argument("--feature_count_table", "-c", required=True)
    silhouette_parser.add_argument("--feature_count_start_column", required=True)
    silhouette_parser.add_argument("--min_number_of_clusters", "-min", required=True, type=int)
    silhouette_parser.add_argument("--max_number_of_clusters", "-max", required=True, type=int)

    pca_parser = subparsers.add_parser("pca", help="principal component analysis")
    pca_parser.set_defaults(func=run_pca)
    pca_parser.add_argument("--feature_count_table", "-f", required=True)
    pca_parser.add_argument("--feature_count_start_column", "-fc", required=True, type=int)
    pca_parser.add_argument("--srna_list_files", "-list", nargs="+")
    pca_parser.add_argument("--output_file_colorized_by_clusters", "-o1", required=True)
    pca_parser.add_argument("--output_file_colorized_by_rna_class", "-o2", required=True)
    pca_parser.add_argument("--output_file_colorized_by_lists", "-o3", required=True)

    t_sne_colored_list_clustering_features_parser = subparsers.add_parser("t_sne", help="This subcommand "
                                                                                        "performs the t-sne dimension"
                                                                                        "reduction")
    t_sne_colored_list_clustering_features_parser.set_defaults(func=run_t_sne_colored_using_different_methods)
    t_sne_colored_list_clustering_features_parser.add_argument("--feature_count_table", "-f", required=True,
                                                               help="This parameter specified the table we "
                                                                    "would like to use."
                                                                    " It can be the normalized or the raw table")
    t_sne_colored_list_clustering_features_parser.add_argument("--feature_count_start_column", "-fc", required=True,
                                                               type=int,
                                                               help="This parameter specified the number "
                                                                    "of the column with the first fraction")
    t_sne_colored_list_clustering_features_parser.add_argument("--perplexity", "-pp", required=True, type=int,
                                                               default=30,
                                                               help="The perplexity is useful to"
                                                                    "balance the attention between "
                                                                    "the global and the  "
                                                                    "local aspects of data. It is better to select "
                                                                    " a value between 5 and 50")
    t_sne_colored_list_clustering_features_parser.add_argument("--srna_list", "-list", nargs="+", default=False,
                                                               help="This parameter allow the user to "
                                                                    "specify a list of features or "
                                                                    "genes we would like to highlight in the plot")
    t_sne_colored_list_clustering_features_parser.add_argument("--cluster_names", "-names", nargs="+", default=False,
                                                               help="This parameter is required only if you provide "
                                                                    "a specific list. It allows the user to "
                                                                    "specify the label on the third plot")
    t_sne_colored_list_clustering_features_parser.add_argument("--color_set", "-set_colors",
                                                               default=bokeh.palettes.Set2,
                                                               help="This parameter can be changed if you are looking "
                                                                    "for a specific color combination "
                                                                    "for your output plot")
    t_sne_colored_list_clustering_features_parser.add_argument("--url_link", "-url", required=False,
                                                               default="https://www.ncbi.nlm.nih.gov/gene/?term=@gene",
                                                               help="This parameter allowed to choose the website"
                                                                    " you would like to open when clicking on a "
                                                                    "specific point in the html plot ")
    t_sne_colored_list_clustering_features_parser.add_argument("--output_file1", "-o1", default=False,
                                                               help="Output plot colorized using clusters information")
    t_sne_colored_list_clustering_features_parser.add_argument("--output_file2", "-o2", default=False,
                                                               help="Output plot colorized using attributes "
                                                                    "information")
    t_sne_colored_list_clustering_features_parser.add_argument("--output_file3", "-o3", default=False,
                                                               help="Output plot colorized using a specific list")

    correlation_rna_protein_parser = subparsers.add_parser("correlation_rnas_protein",
                                                           help="spearman correlation sequencing "
                                                                "data against proteins data")
    correlation_rna_protein_parser.set_defaults(func=correlation_rnas_protein)
    correlation_rna_protein_parser.add_argument("--feature_count_table", "-f", required=True)
    correlation_rna_protein_parser.add_argument("--feature_count_start_column", "-fc", required=True,
                                                type=int)
    correlation_rna_protein_parser.add_argument("--feature_count_end_column", "-fe", type=int)
    correlation_rna_protein_parser.add_argument("--protein_table", "-p", required=True)
    correlation_rna_protein_parser.add_argument("--protein_count_start_column", "-pc", required=True,
                                                type=int)
    correlation_rna_protein_parser.add_argument("--protein_count_end_column", "-pe", type=int)
    correlation_rna_protein_parser.add_argument("--output_file", "-o", default=False,
                                                help="output table")

    correlation_distribution_graph_parser = subparsers.add_parser("correlation_distribution_graph",
                                                                  help="distribution of the "
                                                                       "correlation coefficients")
    correlation_distribution_graph_parser.set_defaults(func=correlation_distribution_graph)
    correlation_distribution_graph_parser.add_argument("--table_with_correlation_coefficient", "-c", required=True)
    correlation_distribution_graph_parser.add_argument("--percentile", "-p", required=True,
                                                       type=int)
    correlation_distribution_graph_parser.add_argument("--output_plot", "-o", required=True)

    plot_network_graph_parser = subparsers.add_parser("plot_network_graph_parser",
                                                      help="network plot sequencing data "
                                                           "vs proteins data")
    plot_network_graph_parser.set_defaults(func=plot_network_graph_parser_rna_protein)
    plot_network_graph_parser.add_argument("--feature_count_table", "-f", required=True)
    plot_network_graph_parser.add_argument("--threshold", "-t", required=True, type=float)
    plot_network_graph_parser.add_argument("--max_size", "-max", required=True,
                                           type=int)
    plot_network_graph_parser.add_argument("--output_plot", "-o")

    clustering_parser_proteins = subparsers.add_parser("clustering_proteins",
                                                       help="unsupervised clustering of Mass spectrometry data")
    clustering_parser_proteins.set_defaults(func=clustering_proteins_data)
    clustering_parser_proteins.add_argument("--feature_count_table", "-f", required=True)
    clustering_parser_proteins.add_argument("--feature_count_start_column", "-fc", required=True, type=int)
    clustering_parser_proteins.add_argument("--feature_count_end_column", "-fe", required=True, type=int)
    clustering_parser_proteins.add_argument("--number_of_clusters", '-nc', required=True, type=int)
    clustering_parser_proteins.add_argument("--clustering_methods", "-cm", required=True,
                                            choices=["k-means", "DBSCAN", 'hierarchical_clustering'])
    clustering_parser_proteins.add_argument("--epsilon", "-e", default=False,
                                            help='only for DBSCAN clustering', type=float)
    clustering_parser_proteins.add_argument("--min_samples", '-ms', default=False,
                                            help='only for DBSCAN clustering', type=int)
    clustering_parser_proteins.add_argument("--output_file", "-o", required=True)

    t_sne_proteins_data_parser = subparsers.add_parser("t_sne_proteins",
                                                       help='t-sne analysis of Mass spectrometry data')
    t_sne_proteins_data_parser.set_defaults(func=t_sne_proteins_f)
    t_sne_proteins_data_parser.add_argument("--feature_count_table", "-f", required=True)
    t_sne_proteins_data_parser.add_argument("--feature_count_start_column", "-fc", required=True,
                                            type=int)
    t_sne_proteins_data_parser.add_argument("--perplexity", "-pp", required=True, type=int)
    t_sne_proteins_data_parser.add_argument("--output_file_colorized_by_clusters", "-o", required=True,
                                            help="output colorized using clusters information")

    correlation_specific_gene_parser = subparsers.add_parser("correlation_specific_gene",
                                                             help="spearman correlation of a "
                                                                  "specific feature against all")
    correlation_specific_gene_parser.set_defaults(func=run_correlation_specific_gene)
    correlation_specific_gene_parser.add_argument('--feature_count_table', '-f', required=True)
    correlation_specific_gene_parser.add_argument("--feature_count_start_column", "-fc", required=True)
    correlation_specific_gene_parser.add_argument("--feature_count_end_column", "-fe", type=int, default=0)
    correlation_specific_gene_parser.add_argument("--name_column_with_genes_name", "-nc", required=True)
    correlation_specific_gene_parser.add_argument("--name", "-name", required=True)
    correlation_specific_gene_parser.add_argument("--output_file", '-o')

    interactive_tsne_plot_parser = subparsers.add_parser("interactive_tsne_plot",
                                                         help="compare the ERCC concentration in mix "
                                                              "with the ERCC reads and take it out the outliers")
    interactive_tsne_plot_parser.set_defaults(func=run_interactive_tsne_plot)
    interactive_tsne_plot_parser.add_argument('--table_with_clusters', '-t', required=True)
    interactive_tsne_plot_parser.add_argument("--start_column", "-sc", required=True)
    interactive_tsne_plot_parser.add_argument("--output_file", '-o')

    correlation_replicates_sequencing_data_parser = subparsers.add_parser("replicates_correlation_sequencing", )
    correlation_replicates_sequencing_data_parser.set_defaults(func=run_replicates_correlation_sequencing)
    correlation_replicates_sequencing_data_parser.add_argument('--table_replicate1', '-r1', required=True)
    correlation_replicates_sequencing_data_parser.add_argument("--table_replicate2", "-r2", required=True)
    correlation_replicates_sequencing_data_parser.add_argument('--table_start_column' "-fc", required=True)
    correlation_replicates_sequencing_data_parser.add_argument('--table_end_column' "-fe", required=True)
    correlation_replicates_sequencing_data_parser.add_argument("--output_table", '-o')
    correlation_replicates_sequencing_data_parser.add_argument("--output_figure", '-f')

    args = parser.parse_args()
    if "func" in dir(args):
        args.func(args)
    else:
        parser.print_help()


def create_project(args):
    projectcreator.create_root_folder("GRADitude")
    projectcreator.create_subfolders("GRADitude", ["input", "output"])
    projectcreator.create_version_file("GRADitude/version.txt", "1.0.0")
    projectcreator.create_root_folder("GRADitude/subCommand")
    projectcreator.create_subfolders("GRADitude/subCommand", ["input", "output"])


def filtering_tables(args):
    min_row_sum_ercc_table.filtering_ercc_table(
        args.ref_feature_count_table,
        args.min_row_sum,
        args.filtered_ref_feature_count_table)


def drop_column(args):
    dropping_specific_columns.dropping_column(args.feature_count_table, args.column_to_drop,
                                              args.output_file)


def normalize_table(args):
    normalize.normalized_count_table(
        args.feature_count_table, args.feature_count_start_column, args.feature_count_end_column,
        args.ref_feature_count_table, args.ref_feature_count_start_column, args.ref_feature_count_end_column,
        args.normalized_table, args.size_factor_table)


def run_correlation_gene_gene(args):
    correlation_between_genes.correlation(args.feature_count_table, args.feature_count_start_column, args.output_file)


def plot_kinetics(args):
    visualizing_kinetics.plot_kinetics(
        args.feature_count_table, args.gene_name, args.feature_count_start_column)


def select_specific_features(args):
    selecting_ncRNAs.selecting_specific_features(args.normalized_table,
                                                 args.feature_count_start_column, args.features, args.output_file)


def generate_k_means_clustering_elbow(args):
    elbow_curve.k_means_clustering_elbow(args.feature_count_table,
                                         args.feature_count_start_column,
                                         args.feature_count_end_column,
                                         args.min_number_of_clusters,
                                         args.max_number_of_clusters, args.output_plots1,
                                         args.output_plots2)


def silhouette_analysis(args):
    silhouette.silhouette_analysis(args.feature_count_table,
                                   args.feature_count_start_column,
                                   args.min_number_of_clusters,
                                   args.max_number_of_clusters)


def run_t_sne_colored_using_different_methods(args):
    t_sne_colored_list_clustering_features.t_sne(args.feature_count_table, args.feature_count_start_column,
                                                 args.perplexity,
                                                 args.srna_list,
                                                 args.cluster_names,
                                                 args.color_set,
                                                 args.url_link,
                                                 args.output_file1,
                                                 args.output_file2,
                                                 args.output_file3)


def run_pca(args):
    PCA_analysis.pca_(args.feature_count_table,
                      args.feature_count_start_column, args.srna_list_files,
                      args.output_file_colorized_by_clusters, args.output_file_colorized_by_rna_class,
                      args.output_file_colorized_by_lists)


def run_scaling(args):
    scaling.scaling_(args.feature_count_table,
                     args.feature_count_start_column, args.feature_count_end_column,
                     args.pseudo_count,
                     args.scaling_method,
                     args.scaled_table)


def run_robust_regression(args):
    robust_regression.robust_regression(args.ref_feature_count_table,
                                        args.concentration_table, args.number_of_outliers,
                                        args.number_of_ercc_in_common, args.used_mix,
                                        args.output_table)


def clustering(args):
    Clustering.clustering(args.feature_count_table, args.feature_count_start_column, args.number_of_clusters,
                          args.pseudo_count, args.clustering_methods,
                          args.epsilon, args.min_samples,
                          args.scaling_method,
                          args.output_file)


def find_min_rows(args):
    min_row_sum.exclude_the_min_row_sum(args.feature_count_table, args.feature_count_start_column,
                                        args.feature_count_end_column, args.min_row,
                                        args.output_file)


def correlation_rnas_protein(args):
    correlation_rna_protein.rna_protein_correlation(args.feature_count_table,
                                                    args.feature_count_start_column, args.feature_count_end_column,
                                                    args.protein_table, args.protein_count_start_column,
                                                    args.protein_count_end_column,
                                                    args.output_file)


def correlation_distribution_graph(args):
    distribution_correlation.distribution_correlation_graph(args.table_with_correlation_coefficient, args.percentile,
                                                            args.output_plot)


def plot_network_graph_parser_rna_protein(args):
    plot_network_graph.plot_network_graph_rna_protein(args.feature_count_table, args.threshold, args.max_size,
                                                      args.output_plot)


def clustering_proteins_data(args):
    clustering_proteins.clustering(args.feature_count_table, args.feature_count_start_column,
                                   args.feature_count_end_column,
                                   args.number_of_clusters,
                                   args.clustering_methods,
                                   args.epsilon, args.min_samples,
                                   args.output_file)


def t_sne_proteins_f(args):
    t_sne_proteins_data.t_sne_pr(args.feature_count_table, args.feature_count_start_column,
                                 args.perplexity,
                                 args.output_file_colorized_by_clusters)


def run_correlation_specific_gene(args):
    correlation_specific_gene.correlation_specific_gene_against_all(args.feature_count_table,
                                                                    args.feature_count_start_column,
                                                                    args.feature_count_end_column,
                                                                    args.name_column_with_genes_name,
                                                                    args.name, args.output_file)


def run_interactive_tsne_plot(args):
    interactive_tsne_plot.interactive_plot(args.table_with_clusters, args.start_column, args.output_file)


def plot_heatmap(args):
    heatmap.plot_heatmap(args.feature_count_table, args.feature_count_start_column,
                         args.y_label, args.output_file)


def run_replicates_correlation_sequencing(args):
    correlation_replicates_sequencing_data.correlation_replicates_sd(args.table_replicate1, args.table_replicate2,
                                                                     args.table_start_column, args.table_end_column,
                                                                     args.output_table, args.output_figure)


main()
